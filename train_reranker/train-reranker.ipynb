{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11680975,"sourceType":"datasetVersion","datasetId":7331259},{"sourceId":11681980,"sourceType":"datasetVersion","datasetId":7331892}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%bash\ngit clone https://github.com/FlagOpen/FlagEmbedding.git\ncd FlagEmbedding\npip install  .[finetune]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!torchrun --nproc_per_node=2 \\\n    -m FlagEmbedding.finetune.reranker.encoder_only.base \\\n    --model_name_or_path BAAI/bge-reranker-v2-m3 \\\n    --train_data \"/kaggle/input/bge-reranker-v2/bge_train_data1 (1).jsonl\" \\\n    --train_group_size 4 \\\n    --query_max_len 40 \\\n    --passage_max_len 512 \\\n    --max_len 700 \\\n    --knowledge_distillation False \\\n    --output_dir ./test_encoder_only_base_bge-reranker-base \\\n    --overwrite_output_dir \\\n    --learning_rate 2e-5 \\\n    --fp16 \\\n    --num_train_epochs 5 \\\n    --per_device_train_batch_size 1 \\\n    --gradient_accumulation_steps 2 \\\n    --dataloader_drop_last True \\\n    --warmup_ratio 0.1 \\\n    --weight_decay 0.01 \\\n    --logging_steps 30 \\\n    --save_steps 1100 \\\n    --report_to none\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T07:43:54.133244Z","iopub.execute_input":"2025-05-05T07:43:54.133774Z","iopub.status.idle":"2025-05-05T08:49:07.477446Z","shell.execute_reply.started":"2025-05-05T07:43:54.133755Z","shell.execute_reply":"2025-05-05T08:49:07.476492Z"}},"outputs":[{"name":"stdout","text":"W0505 07:43:55.818000 552 torch/distributed/run.py:793] \nW0505 07:43:55.818000 552 torch/distributed/run.py:793] *****************************************\nW0505 07:43:55.818000 552 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \nW0505 07:43:55.818000 552 torch/distributed/run.py:793] *****************************************\n2025-05-05 07:43:59.934883: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-05-05 07:43:59.934909: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746431039.957858     555 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746431039.957880     554 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746431039.964751     554 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1746431039.964753     555 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[2025-05-05 07:44:04,196] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-05-05 07:44:04,197] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n/usr/local/lib/python3.11/dist-packages/FlagEmbedding/finetune/reranker/encoder_only/base/runner.py:68: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `EncoderOnlyRerankerTrainer.__init__`. Use `processing_class` instead.\n  trainer = EncoderOnlyRerankerTrainer(\n/usr/local/lib/python3.11/dist-packages/FlagEmbedding/finetune/reranker/encoder_only/base/runner.py:68: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `EncoderOnlyRerankerTrainer.__init__`. Use `processing_class` instead.\n  trainer = EncoderOnlyRerankerTrainer(\n  0%|                                                  | 0/3585 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\nYou're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n[rank1]:[W505 07:44:11.518170039 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n[rank0]:[W505 07:44:11.520451929 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n{'loss': 0.7975, 'grad_norm': 32.568443298339844, 'learning_rate': 1.392757660167131e-06, 'epoch': 0.04}\n{'loss': 0.7981, 'grad_norm': 73.00859069824219, 'learning_rate': 3.008356545961003e-06, 'epoch': 0.08}\n{'loss': 0.6331, 'grad_norm': 22.23833656311035, 'learning_rate': 4.67966573816156e-06, 'epoch': 0.13}\n{'loss': 0.9817, 'grad_norm': 89.57894134521484, 'learning_rate': 6.350974930362117e-06, 'epoch': 0.17}\n{'loss': 0.7666, 'grad_norm': 13.48413372039795, 'learning_rate': 8.022284122562675e-06, 'epoch': 0.21}\n{'loss': 0.8099, 'grad_norm': 46.50400161743164, 'learning_rate': 9.693593314763233e-06, 'epoch': 0.25}\n{'loss': 0.6129, 'grad_norm': 27.179513931274414, 'learning_rate': 1.1364902506963789e-05, 'epoch': 0.29}\n{'loss': 0.7712, 'grad_norm': 133.0576171875, 'learning_rate': 1.3036211699164346e-05, 'epoch': 0.33}\n{'loss': 0.7997, 'grad_norm': 83.40876007080078, 'learning_rate': 1.4651810584958219e-05, 'epoch': 0.38}\n{'loss': 0.7894, 'grad_norm': 63.97444152832031, 'learning_rate': 1.6323119777158775e-05, 'epoch': 0.42}\n{'loss': 0.5024, 'grad_norm': 131.96206665039062, 'learning_rate': 1.7994428969359333e-05, 'epoch': 0.46}\n{'loss': 0.6539, 'grad_norm': 47.605953216552734, 'learning_rate': 1.966573816155989e-05, 'epoch': 0.5}\n{'loss': 0.806, 'grad_norm': 121.29617309570312, 'learning_rate': 1.9851208927464352e-05, 'epoch': 0.54}\n{'loss': 0.7888, 'grad_norm': 57.784912109375, 'learning_rate': 1.9665220086794793e-05, 'epoch': 0.59}\n{'loss': 0.969, 'grad_norm': 94.63754272460938, 'learning_rate': 1.9479231246125233e-05, 'epoch': 0.63}\n{'loss': 0.873, 'grad_norm': 50.644222259521484, 'learning_rate': 1.9293242405455673e-05, 'epoch': 0.67}\n{'loss': 0.6497, 'grad_norm': 45.12379837036133, 'learning_rate': 1.9107253564786113e-05, 'epoch': 0.71}\n{'loss': 0.8657, 'grad_norm': 72.11088562011719, 'learning_rate': 1.8921264724116553e-05, 'epoch': 0.75}\n{'loss': 0.6757, 'grad_norm': 22.538619995117188, 'learning_rate': 1.8735275883446994e-05, 'epoch': 0.79}\n{'loss': 0.6761, 'grad_norm': 2.57439923286438, 'learning_rate': 1.8549287042777434e-05, 'epoch': 0.84}\n{'loss': 0.7889, 'grad_norm': 5.099902153015137, 'learning_rate': 1.8363298202107874e-05, 'epoch': 0.88}\n{'loss': 0.7752, 'grad_norm': 73.90702056884766, 'learning_rate': 1.8177309361438314e-05, 'epoch': 0.92}\n{'loss': 0.744, 'grad_norm': 46.83055877685547, 'learning_rate': 1.7991320520768754e-05, 'epoch': 0.96}\n{'loss': 0.5478, 'grad_norm': 42.72808074951172, 'learning_rate': 1.7805331680099194e-05, 'epoch': 1.0}\n{'loss': 0.4641, 'grad_norm': 0.6765221953392029, 'learning_rate': 1.7619342839429635e-05, 'epoch': 1.05}\n{'loss': 0.3118, 'grad_norm': 63.37253189086914, 'learning_rate': 1.7433353998760075e-05, 'epoch': 1.09}\n{'loss': 0.556, 'grad_norm': 1.922337532043457, 'learning_rate': 1.7247365158090515e-05, 'epoch': 1.13}\n{'loss': 0.3127, 'grad_norm': 69.26212310791016, 'learning_rate': 1.7061376317420955e-05, 'epoch': 1.17}\n{'loss': 0.4618, 'grad_norm': 0.09310135990381241, 'learning_rate': 1.6875387476751395e-05, 'epoch': 1.21}\n{'loss': 0.3834, 'grad_norm': 0.11323978006839752, 'learning_rate': 1.6689398636081836e-05, 'epoch': 1.26}\n{'loss': 0.2805, 'grad_norm': 0.9260662794113159, 'learning_rate': 1.6503409795412276e-05, 'epoch': 1.3}\n{'loss': 0.4874, 'grad_norm': 38.6672248840332, 'learning_rate': 1.6317420954742716e-05, 'epoch': 1.34}\n{'loss': 0.4232, 'grad_norm': 122.89414978027344, 'learning_rate': 1.6131432114073156e-05, 'epoch': 1.38}\n{'loss': 0.2808, 'grad_norm': 65.33963012695312, 'learning_rate': 1.5945443273403596e-05, 'epoch': 1.42}\n{'loss': 0.7605, 'grad_norm': 40.9065055847168, 'learning_rate': 1.5759454432734037e-05, 'epoch': 1.46}\n{'loss': 0.4068, 'grad_norm': 15.538698196411133, 'learning_rate': 1.5573465592064477e-05, 'epoch': 1.51}\n 31%|███████████▉                           | 1100/3585 [19:52<45:33,  1.10s/it]Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n{'loss': 0.3585, 'grad_norm': 4.766261100769043, 'learning_rate': 1.5387476751394917e-05, 'epoch': 1.55}\n{'loss': 0.4215, 'grad_norm': 116.98262023925781, 'learning_rate': 1.5201487910725359e-05, 'epoch': 1.59}\n{'loss': 0.3977, 'grad_norm': 23.80855941772461, 'learning_rate': 1.5015499070055799e-05, 'epoch': 1.63}\n{'loss': 0.5333, 'grad_norm': 149.7757110595703, 'learning_rate': 1.4829510229386238e-05, 'epoch': 1.67}\n{'loss': 0.8169, 'grad_norm': 90.84175872802734, 'learning_rate': 1.4643521388716678e-05, 'epoch': 1.72}\n{'loss': 0.7183, 'grad_norm': 50.66148376464844, 'learning_rate': 1.4457532548047118e-05, 'epoch': 1.76}\n{'loss': 0.7156, 'grad_norm': 109.52410125732422, 'learning_rate': 1.4271543707377558e-05, 'epoch': 1.8}\n{'loss': 0.3976, 'grad_norm': 74.30709075927734, 'learning_rate': 1.4091754494730317e-05, 'epoch': 1.84}\n{'loss': 0.6742, 'grad_norm': 98.49983215332031, 'learning_rate': 1.3905765654060757e-05, 'epoch': 1.88}\n{'loss': 0.6313, 'grad_norm': 74.05767059326172, 'learning_rate': 1.3719776813391197e-05, 'epoch': 1.92}\n{'loss': 0.4706, 'grad_norm': 139.7386016845703, 'learning_rate': 1.3533787972721637e-05, 'epoch': 1.97}\n{'loss': 0.502, 'grad_norm': 0.06259357184171677, 'learning_rate': 1.3347799132052077e-05, 'epoch': 2.01}\n{'loss': 0.2307, 'grad_norm': 0.19518867135047913, 'learning_rate': 1.3161810291382518e-05, 'epoch': 2.05}\n{'loss': 0.2055, 'grad_norm': 29.481529235839844, 'learning_rate': 1.2975821450712958e-05, 'epoch': 2.09}\n{'loss': 0.0859, 'grad_norm': 3.097910165786743, 'learning_rate': 1.2789832610043398e-05, 'epoch': 2.13}\n{'loss': 0.1791, 'grad_norm': 3.5064427852630615, 'learning_rate': 1.2603843769373838e-05, 'epoch': 2.18}\n{'loss': 0.2598, 'grad_norm': 58.10625076293945, 'learning_rate': 1.2417854928704278e-05, 'epoch': 2.22}\n{'loss': 0.2557, 'grad_norm': 1.992246150970459, 'learning_rate': 1.2231866088034719e-05, 'epoch': 2.26}\n{'loss': 0.3541, 'grad_norm': 100.415283203125, 'learning_rate': 1.2045877247365159e-05, 'epoch': 2.3}\n{'loss': 0.1986, 'grad_norm': 25.96088981628418, 'learning_rate': 1.1866088034717917e-05, 'epoch': 2.34}\n{'loss': 0.1673, 'grad_norm': 0.14320509135723114, 'learning_rate': 1.1680099194048358e-05, 'epoch': 2.38}\n{'loss': 0.1983, 'grad_norm': 0.8595238327980042, 'learning_rate': 1.1494110353378798e-05, 'epoch': 2.43}\n{'loss': 0.4854, 'grad_norm': 40.174407958984375, 'learning_rate': 1.1308121512709238e-05, 'epoch': 2.47}\n{'loss': 0.4022, 'grad_norm': 4.724306583404541, 'learning_rate': 1.1122132672039678e-05, 'epoch': 2.51}\n{'loss': 0.3477, 'grad_norm': 83.95266723632812, 'learning_rate': 1.0936143831370118e-05, 'epoch': 2.55}\n{'loss': 0.4255, 'grad_norm': 0.13944898545742035, 'learning_rate': 1.0750154990700559e-05, 'epoch': 2.59}\n{'loss': 0.4977, 'grad_norm': 140.54664611816406, 'learning_rate': 1.0564166150030999e-05, 'epoch': 2.64}\n{'loss': 0.1254, 'grad_norm': 3.3817358016967773, 'learning_rate': 1.0378177309361439e-05, 'epoch': 2.68}\n{'loss': 0.3712, 'grad_norm': 1.0204029083251953, 'learning_rate': 1.0192188468691879e-05, 'epoch': 2.72}\n{'loss': 0.5733, 'grad_norm': 111.90616607666016, 'learning_rate': 1.000619962802232e-05, 'epoch': 2.76}\n{'loss': 0.3635, 'grad_norm': 32.4826545715332, 'learning_rate': 9.82021078735276e-06, 'epoch': 2.8}\n{'loss': 0.2027, 'grad_norm': 10.966970443725586, 'learning_rate': 9.6342219466832e-06, 'epoch': 2.85}\n{'loss': 0.313, 'grad_norm': 122.32735443115234, 'learning_rate': 9.44823310601364e-06, 'epoch': 2.89}\n{'loss': 0.2431, 'grad_norm': 38.697818756103516, 'learning_rate': 9.26224426534408e-06, 'epoch': 2.93}\n{'loss': 0.3253, 'grad_norm': 0.5567869544029236, 'learning_rate': 9.07625542467452e-06, 'epoch': 2.97}\n{'loss': 0.1376, 'grad_norm': 4.574095726013184, 'learning_rate': 8.89026658400496e-06, 'epoch': 3.01}\n{'loss': 0.047, 'grad_norm': 0.10474938154220581, 'learning_rate': 8.7042777433354e-06, 'epoch': 3.05}\n 61%|███████████████████████▉               | 2200/3585 [39:44<24:22,  1.06s/it]Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n{'loss': 0.0683, 'grad_norm': 9.14975357055664, 'learning_rate': 8.51828890266584e-06, 'epoch': 3.1}\n{'loss': 0.0476, 'grad_norm': 0.05768025666475296, 'learning_rate': 8.332300061996281e-06, 'epoch': 3.14}\n{'loss': 0.1582, 'grad_norm': 0.39699599146842957, 'learning_rate': 8.146311221326721e-06, 'epoch': 3.18}\n{'loss': 0.0594, 'grad_norm': 0.41087260842323303, 'learning_rate': 7.960322380657161e-06, 'epoch': 3.22}\n{'loss': 0.0519, 'grad_norm': 1.393997311592102, 'learning_rate': 7.774333539987602e-06, 'epoch': 3.26}\n{'loss': 0.0771, 'grad_norm': 0.08498869091272354, 'learning_rate': 7.588344699318042e-06, 'epoch': 3.31}\n{'loss': 0.3453, 'grad_norm': 0.8494588732719421, 'learning_rate': 7.402355858648481e-06, 'epoch': 3.35}\n{'loss': 0.1246, 'grad_norm': 12.495911598205566, 'learning_rate': 7.216367017978921e-06, 'epoch': 3.39}\n{'loss': 0.0807, 'grad_norm': 1.3345787525177002, 'learning_rate': 7.030378177309361e-06, 'epoch': 3.43}\n{'loss': 0.1433, 'grad_norm': 22.339323043823242, 'learning_rate': 6.844389336639802e-06, 'epoch': 3.47}\n{'loss': 0.1143, 'grad_norm': 4.726256370544434, 'learning_rate': 6.658400495970242e-06, 'epoch': 3.51}\n{'loss': 0.1827, 'grad_norm': 0.051098547875881195, 'learning_rate': 6.472411655300682e-06, 'epoch': 3.56}\n{'loss': 0.2368, 'grad_norm': 0.0001970189478015527, 'learning_rate': 6.286422814631122e-06, 'epoch': 3.6}\n{'loss': 0.2452, 'grad_norm': 1.3852251768112183, 'learning_rate': 6.100433973961562e-06, 'epoch': 3.64}\n{'loss': 0.1971, 'grad_norm': 0.00803871639072895, 'learning_rate': 5.9144451332920025e-06, 'epoch': 3.68}\n{'loss': 0.1857, 'grad_norm': 26.186708450317383, 'learning_rate': 5.728456292622443e-06, 'epoch': 3.72}\n{'loss': 0.1721, 'grad_norm': 157.35171508789062, 'learning_rate': 5.542467451952883e-06, 'epoch': 3.77}\n{'loss': 0.2365, 'grad_norm': 0.005442513152956963, 'learning_rate': 5.356478611283323e-06, 'epoch': 3.81}\n{'loss': 0.1896, 'grad_norm': 0.011249261908233166, 'learning_rate': 5.170489770613763e-06, 'epoch': 3.85}\n{'loss': 0.0394, 'grad_norm': 5.60353422164917, 'learning_rate': 4.9845009299442035e-06, 'epoch': 3.89}\n{'loss': 0.0697, 'grad_norm': 10.209983825683594, 'learning_rate': 4.798512089274644e-06, 'epoch': 3.93}\n{'loss': 0.3291, 'grad_norm': 1.0592576265335083, 'learning_rate': 4.612523248605084e-06, 'epoch': 3.97}\n{'loss': 0.0575, 'grad_norm': 4.225447177886963, 'learning_rate': 4.426534407935524e-06, 'epoch': 4.02}\n{'loss': 0.0454, 'grad_norm': 2.159212589263916, 'learning_rate': 4.240545567265964e-06, 'epoch': 4.06}\n{'loss': 0.0019, 'grad_norm': 0.8314790725708008, 'learning_rate': 4.054556726596404e-06, 'epoch': 4.1}\n{'loss': 0.0033, 'grad_norm': 0.0008762713987380266, 'learning_rate': 3.868567885926845e-06, 'epoch': 4.14}\n{'loss': 0.029, 'grad_norm': 0.6422022581100464, 'learning_rate': 3.682579045257285e-06, 'epoch': 4.18}\n{'loss': 0.0597, 'grad_norm': 0.005046140402555466, 'learning_rate': 3.496590204587725e-06, 'epoch': 4.23}\n{'loss': 0.0761, 'grad_norm': 0.06895293295383453, 'learning_rate': 3.310601363918165e-06, 'epoch': 4.27}\n{'loss': 0.1777, 'grad_norm': 38.74474334716797, 'learning_rate': 3.1246125232486054e-06, 'epoch': 4.31}\n{'loss': 0.0233, 'grad_norm': 0.001170502626337111, 'learning_rate': 2.9386236825790455e-06, 'epoch': 4.35}\n{'loss': 0.0138, 'grad_norm': 5.050951585872099e-06, 'learning_rate': 2.7526348419094857e-06, 'epoch': 4.39}\n{'loss': 0.0712, 'grad_norm': 0.0007568077417090535, 'learning_rate': 2.566646001239926e-06, 'epoch': 4.44}\n{'loss': 0.002, 'grad_norm': 7.355659484863281, 'learning_rate': 2.380657160570366e-06, 'epoch': 4.48}\n{'loss': 0.0412, 'grad_norm': 0.5271725654602051, 'learning_rate': 2.1946683199008063e-06, 'epoch': 4.52}\n{'loss': 0.1414, 'grad_norm': 163.00088500976562, 'learning_rate': 2.0086794792312465e-06, 'epoch': 4.56}\n{'loss': 0.1546, 'grad_norm': 0.09353336691856384, 'learning_rate': 1.8226906385616862e-06, 'epoch': 4.6}\n 92%|███████████████████████████████████▉   | 3300/3585 [59:30<05:13,  1.10s/it]Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n{'loss': 0.0802, 'grad_norm': 0.004930355120450258, 'learning_rate': 1.6367017978921264e-06, 'epoch': 4.64}\n{'loss': 0.0313, 'grad_norm': 0.0029698959551751614, 'learning_rate': 1.4507129572225666e-06, 'epoch': 4.69}\n{'loss': 0.1008, 'grad_norm': 5.002918243408203, 'learning_rate': 1.264724116553007e-06, 'epoch': 4.73}\n{'loss': 0.0035, 'grad_norm': 0.011326153762638569, 'learning_rate': 1.0787352758834472e-06, 'epoch': 4.77}\n{'loss': 0.1415, 'grad_norm': 0.08600539714097977, 'learning_rate': 8.927464352138872e-07, 'epoch': 4.81}\n{'loss': 0.1296, 'grad_norm': 0.6029607653617859, 'learning_rate': 7.067575945443274e-07, 'epoch': 4.85}\n{'loss': 0.1747, 'grad_norm': 78.56023406982422, 'learning_rate': 5.207687538747676e-07, 'epoch': 4.9}\n{'loss': 0.3312, 'grad_norm': 0.04964547976851463, 'learning_rate': 3.347799132052077e-07, 'epoch': 4.94}\n{'loss': 0.0089, 'grad_norm': 0.027212146669626236, 'learning_rate': 1.4879107253564788e-07, 'epoch': 4.98}\n100%|█████████████████████████████████████| 3585/3585 [1:04:47<00:00,  1.01s/it][rank0]: Traceback (most recent call last):\n[rank0]:   File \"<frozen runpy>\", line 198, in _run_module_as_main\n[rank0]:   File \"<frozen runpy>\", line 88, in _run_code\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/FlagEmbedding/finetune/reranker/encoder_only/base/__main__.py\", line 27, in <module>\n[rank0]:     main()\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/FlagEmbedding/finetune/reranker/encoder_only/base/__main__.py\", line 23, in main\n[rank0]:     runner.run()\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/FlagEmbedding/abc/finetune/reranker/AbsRunner.py\", line 142, in run\n[rank0]:     self.trainer.train(resume_from_checkpoint=self.training_args.resume_from_checkpoint)\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2245, in train\n[rank0]:     return inner_training_loop(\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2627, in _inner_training_loop\n[rank0]:     self._maybe_log_save_evaluate(\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 3103, in _maybe_log_save_evaluate\n[rank0]:     self._save_checkpoint(model, trial)\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 3200, in _save_checkpoint\n[rank0]:     self.save_model(output_dir, _internal_call=True)\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 3902, in save_model\n[rank0]:     self._save(output_dir)\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/FlagEmbedding/finetune/reranker/encoder_only/base/trainer.py\", line 32, in _save\n[rank0]:     self.model.save_pretrained(output_dir)\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/FlagEmbedding/abc/finetune/reranker/AbsModeling.py\", line 132, in save_pretrained\n[rank0]:     return self.model.save_pretrained(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 3564, in save_pretrained\n[rank0]:     safe_save_file(shard, os.path.join(save_directory, shard_file), metadata={\"format\": \"pt\"})\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/safetensors/torch.py\", line 286, in save_file\n[rank0]:     serialize_file(_flatten(tensors), filename, metadata=metadata)\n[rank0]: safetensors_rust.SafetensorError: Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })\n100%|█████████████████████████████████████| 3585/3585 [1:04:52<00:00,  1.09s/it]\n[rank0]:[W505 08:49:03.512992254 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\nW0505 08:49:06.709000 552 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 555 closing signal SIGTERM\nE0505 08:49:07.034000 552 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 554) of binary: /usr/bin/python3\nTraceback (most recent call last):\n  File \"/usr/local/bin/torchrun\", line 10, in <module>\n    sys.exit(main())\n             ^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 919, in main\n    run(args)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 910, in run\n    elastic_launch(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n    raise ChildFailedError(\ntorch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n============================================================\nFlagEmbedding.finetune.reranker.encoder_only.base FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2025-05-05_08:49:06\n  host      : 984b0dcca451\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 554)\n  error_file: <N/A>\n  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n============================================================\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!pip install huggingface_hub --upgrade\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T07:13:17.929274Z","iopub.execute_input":"2025-05-05T07:13:17.929477Z","iopub.status.idle":"2025-05-05T07:13:21.350103Z","shell.execute_reply.started":"2025-05-05T07:13:17.929458Z","shell.execute_reply":"2025-05-05T07:13:21.348959Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.12.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import shutil\nimport os\n\n# Đường dẫn đến thư mục gốc chứa các checkpoint\n\n# Các thư mục cần xóa\nfolders_to_delete = [\"checkpoint-1100\"]\n\nfor folder_name in folders_to_delete:\n    folder_path = os.path.join(base_dir, folder_name)\n    if os.path.exists(folder_path):\n        shutil.rmtree(folder_path)\n        print(f\"Đã xóa: {folder_path}\")\n    else:\n        print(f\"Không tìm thấy: {folder_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T08:49:30.984383Z","iopub.execute_input":"2025-05-05T08:49:30.984653Z","iopub.status.idle":"2025-05-05T08:49:31.159839Z","shell.execute_reply.started":"2025-05-05T08:49:30.984628Z","shell.execute_reply":"2025-05-05T08:49:31.158979Z"}},"outputs":[{"name":"stdout","text":"Đã xóa: ./test_encoder_only_base_bge-reranker-base/checkpoint-1100\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# import shutil\n# import os\n# base_dir = \"./test_encoder_only_base_bge-reranker-base\"\n\n# if os.path.exists(base_dir):\n#     shutil.rmtree(base_dir)\n#     print(f\"Đã xóa: {base_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T07:43:16.108012Z","iopub.execute_input":"2025-05-05T07:43:16.108323Z","iopub.status.idle":"2025-05-05T07:43:17.474401Z","shell.execute_reply.started":"2025-05-05T07:43:16.108298Z","shell.execute_reply":"2025-05-05T07:43:17.473583Z"}},"outputs":[{"name":"stdout","text":"Đã xóa: ./test_encoder_only_base_bge-reranker-base\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from huggingface_hub import create_repo, upload_folder\nimport os\n\nrepo_id = \"davicn81/bge-v2-m3-2200\"\n\n# Tạo repo nếu chưa có\ncreate_repo(repo_id=repo_id, repo_type=\"model\", exist_ok=True)\n\n# Đường dẫn thư mục chứa model\nmodel_dir = \"./test_encoder_only_base_bge-reranker-base/checkpoint-2200\"\n\n# Lọc danh sách file cần thiết\nneeded_files = [\n    \"config.json\",\n    \"model.safetensors\",\n    \"tokenizer_config.json\",\n    \"tokenizer.json\",\n    \"sentencepiece.bpe.model\",\n    \"special_tokens_map.json\",\n]\n\n# Tạo một thư mục tạm chỉ chứa các file này\nimport shutil\nfrom pathlib import Path\n\nupload_dir = \"./temp_upload\"\nos.makedirs(upload_dir, exist_ok=True)\n\nfor file in needed_files:\n    src = os.path.join(model_dir, file)\n    dst = os.path.join(upload_dir, file)\n    if os.path.exists(src):\n        shutil.copy(src, dst)\n\n# Upload thư mục này lên Hugging Face\nupload_folder(\n    folder_path=upload_dir,\n    repo_id=repo_id,\n    commit_message=\"Upload fine-tuned reranker model with essential files only\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T08:49:46.253844Z","iopub.execute_input":"2025-05-05T08:49:46.254112Z","iopub.status.idle":"2025-05-05T08:50:46.303297Z","shell.execute_reply.started":"2025-05-05T08:49:46.254090Z","shell.execute_reply":"2025-05-05T08:50:46.302546Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dadc74dd52754fa3b4927981b7548502"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5e42bcc2ebf4966b18cffa645ec05a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a0363344b2a41439a87990fecfc33a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19848062b6c8475494ae064dc7337068"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/davicn81/bge-v2-m3-2200/commit/aa723fef816ca261fefc3dd049fd539b5673c19c', commit_message='Upload fine-tuned reranker model with essential files only', commit_description='', oid='aa723fef816ca261fefc3dd049fd539b5673c19c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/davicn81/bge-v2-m3-2200', endpoint='https://huggingface.co', repo_type='model', repo_id='davicn81/bge-v2-m3-2200'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from huggingface_hub import create_repo, upload_folder\nimport os\n\nrepo_id = \"davicn81/bge-v2-m3-3300\"\n\n# Tạo repo nếu chưa có\ncreate_repo(repo_id=repo_id, repo_type=\"model\", exist_ok=True)\n\n# Đường dẫn thư mục chứa model\nmodel_dir = \"./test_encoder_only_base_bge-reranker-base/checkpoint-3300\"\n\n# Lọc danh sách file cần thiết\nneeded_files = [\n    \"config.json\",\n    \"model.safetensors\",\n    \"tokenizer_config.json\",\n    \"tokenizer.json\",\n    \"sentencepiece.bpe.model\",\n    \"special_tokens_map.json\",\n]\n\n# Tạo một thư mục tạm chỉ chứa các file này\nimport shutil\nfrom pathlib import Path\n\nupload_dir = \"./temp_upload\"\nos.makedirs(upload_dir, exist_ok=True)\n\nfor file in needed_files:\n    src = os.path.join(model_dir, file)\n    dst = os.path.join(upload_dir, file)\n    if os.path.exists(src):\n        shutil.copy(src, dst)\n\n# Upload thư mục này lên Hugging Face\nupload_folder(\n    folder_path=upload_dir,\n    repo_id=repo_id,\n    commit_message=\"Upload fine-tuned reranker model with essential files only\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T08:50:46.304542Z","iopub.execute_input":"2025-05-05T08:50:46.304960Z","iopub.status.idle":"2025-05-05T08:51:39.703978Z","shell.execute_reply.started":"2025-05-05T08:50:46.304942Z","shell.execute_reply":"2025-05-05T08:51:39.703408Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b32a7134a3ed407183747a829807fe4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26d8d52321a149bfbe3cc78e7ab23d3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb578f35614d44ce8380b8070bea3483"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f9e36ee58464c69ad2e3ff672d41cc2"}},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/davicn81/bge-v2-m3-3300/commit/968cb37c02d1b40e9985d9eabc087af29afa09ed', commit_message='Upload fine-tuned reranker model with essential files only', commit_description='', oid='968cb37c02d1b40e9985d9eabc087af29afa09ed', pr_url=None, repo_url=RepoUrl('https://huggingface.co/davicn81/bge-v2-m3-3300', endpoint='https://huggingface.co', repo_type='model', repo_id='davicn81/bge-v2-m3-3300'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":14}]}